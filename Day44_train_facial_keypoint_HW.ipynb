{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Day44_train_facial_keypoint_Sample.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39esQJwIg_ge",
        "colab_type": "text"
      },
      "source": [
        "### 範例\n",
        "接下來的程式碼會示範如何定義一個簡單的 CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSmkZBx6g_gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zH7rOqhg_hA",
        "colab_type": "code",
        "outputId": "237b2019-543a-4aba-e821-359b1b2e203a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "# 使用 colab 環境的同學請執行以下程式碼\n",
        "%tensorflow_version 1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import os\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive') # 將 google drive 掛載在 colob，\n",
        "%cd 'gdrive/My Drive'\n",
        "%cd cupoy_cv_part4 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "1.15.0\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive\n",
            "/content/gdrive/My Drive/cupoy_cv_part4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDp8bAYQhemJ",
        "colab_type": "code",
        "outputId": "389f1c38-1013-437f-8f0c-a4b46faf99a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%pwd\n",
        "%cd cupoy_cv_part4 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'cupoy_cv_part4'\n",
            "/content/gdrive/My Drive/cupoy_cv_part4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYJ0vCGBg_hO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 讀取資料集以及做前處理的函數\n",
        "def load_data(dirname):\n",
        "    # 讀取 csv 文件\n",
        "    data = pd.read_csv(dirname)\n",
        "    # 過濾有缺失值的 row\n",
        "    data = data.dropna()\n",
        "\n",
        "    # 將圖片像素值讀取為 numpy array 的形態\n",
        "    data['Image'] = data['Image'].apply(lambda img: np.fromstring(img, sep=' ')).values \n",
        "\n",
        "    # 單獨把圖像 array 抽取出來\n",
        "    imgs = np.vstack(data['Image'].values)/255\n",
        "    # reshape 為 96 x 96\n",
        "    imgs = imgs.reshape(data.shape[0], 96, 96)\n",
        "    # 轉換為 float\n",
        "    imgs = imgs.astype(np.float32)\n",
        "    \n",
        "    # 提取坐標的部分\n",
        "    points = data[data.columns[:-1]].values\n",
        "\n",
        "    # 轉換為 float\n",
        "    points = points.astype(np.float32)\n",
        "\n",
        "    # normalize 坐標值到 [-0.5, 0.5]\n",
        "    points = points/96 - 0.5\n",
        "    \n",
        "    return imgs, points"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unxM3uLBg_hY",
        "colab_type": "code",
        "outputId": "530f5839-d9ef-4426-a04a-a50dd401137a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# 讀取資料\n",
        "imgs_train, points_train = load_data(dirname = 'training.csv')\n",
        "print(\"圖像資料:\", imgs_train.shape, \"\\n關鍵點資料:\", points_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "圖像資料: (2140, 96, 96) \n",
            "關鍵點資料: (2140, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNYnvOeKg_hl",
        "colab_type": "code",
        "outputId": "2b816e69-f1cc-4b07-ed72-9e6a301c9690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USnulPuqg_hw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 回傳定義好的 model 的函數\n",
        "def get_model():\n",
        "    # 定義人臉關鍵點檢測網路\n",
        "    model = Sequential()\n",
        "\n",
        "    # 定義神經網路的輸入\n",
        "    model.add(Conv2D(filters=16, kernel_size=3, activation='relu', input_shape=(96, 96, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "    model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "    model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "    model.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # 最後輸出 30 維的向量，也就是 15 個關鍵點的值\n",
        "    model.add(Dense(30))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbFDQeLig_h5",
        "colab_type": "code",
        "outputId": "c7d4494b-9c4c-414f-cb35-e667851c2aee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "model = get_model()\n",
        "# 配置 loss funtion 和 optimizer\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQCTt7gmg_iC",
        "colab_type": "code",
        "outputId": "a36da5c5-cb14-4657-ec8b-c0953050c653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        }
      },
      "source": [
        "# 印出網路結構\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 94, 94, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 47, 47, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 45, 45, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 22, 22, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 20, 20, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 30)                15390     \n",
            "=================================================================\n",
            "Total params: 1,424,286\n",
            "Trainable params: 1,424,286\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XREp9RhVg_iM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, History\n",
        "# model checkpoint \n",
        "checkpoint = ModelCheckpoint('best_weights.h5', verbose=1, save_best_only=True)\n",
        "hist = History()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA1Yyp-sg_iX",
        "colab_type": "code",
        "outputId": "8f6ccb7c-c4ee-43c5-fafa-dbb11d5307d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 1712 samples, validate on 428 samples\n",
            "Epoch 1/150\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 0.0065 - val_loss: 0.0022\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00218, saving model to best_weights.h5\n",
            "Epoch 2/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.00218 to 0.00189, saving model to best_weights.h5\n",
            "Epoch 3/150\n",
            " 320/1712 [====>.........................] - ETA: 9s - loss: 0.0013 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-15-605fe3cd0822>\", line 4, in <module>\n",
            "    shuffle=True, epochs=150, verbose=1)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1178, in fit\n",
            "    validation_freq=validation_freq)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\", line 204, in fit_loop\n",
            "    outs = fit_function(ins_batch)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2979, in __call__\n",
            "    return self._call(inputs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2937, in _call\n",
            "    fetched = self._callable_fn(*array_vals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1472, in __call__\n",
            "    run_metadata_ptr)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 733, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
            "    module = self._load()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 44, in _load\n",
            "    module = _importlib.import_module(self.__name__)\n",
            "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/__init__.py\", line 108, in <module>\n",
            "    from tensorflow.contrib import cloud\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cloud/__init__.py\", line 24, in <module>\n",
            "    from tensorflow.contrib.cloud.python.ops.bigquery_reader_ops import *\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cloud/__init__.py\", line 28, in <module>\n",
            "    from tensorflow.contrib.bigtable.python.ops.bigtable_api import BigtableClient\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/bigtable/__init__.py\", line 29, in <module>\n",
            "    from tensorflow.contrib.bigtable.python.ops.bigtable_api import BigtableClient\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/bigtable/python/ops/bigtable_api.py\", line 44, in <module>\n",
            "    resource_loader.get_path_to_datafile(\"_bigtable.so\"))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/util/loader.py\", line 56, in load_op_library\n",
            "    ret = load_library.load_op_library(path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/load_library.py\", line 78, in load_op_library\n",
            "    exec(wrappers, module.__dict__)\n",
            "  File \"<string>\", line 4, in <module>\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4MQAMh2g_ij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss 值的圖\n",
        "plt.title('Optimizer : Adam', fontsize=10)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.plot(hist_model.history['loss'], color='b', label='Training Loss')\n",
        "plt.plot(hist_model.history['val_loss'], color='r', label='Validation Loss')\n",
        "plt.legend(loc='upper right')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbCW4w37g_it",
        "colab_type": "text"
      },
      "source": [
        "### 觀察 model 在 testing 上的結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDvOvRong_ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 讀取測試資料集\n",
        "imgs_test, _ = load_data(dirname = 'test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM5KzDd5g_i8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 在灰階圖像上畫關鍵點的函數\n",
        "def plot_keypoints(img, points):\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    for i in range(0,30,2):\n",
        "        plt.scatter((points[i] + 0.5)*96, (points[i+1]+0.5)*96, color='red')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7uZOOOLg_jH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(15,15))\n",
        "# 在測試集圖片上用剛剛訓練好的模型做關鍵點的預測\n",
        "points_test = model.predict(imgs_test.reshape(imgs_test.shape[0], 96, 96, 1))\n",
        "\n",
        "for i in range(16):\n",
        "    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
        "    plot_keypoints(imgs_test[i], np.squeeze(points_test[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik03ILMcg_jO",
        "colab_type": "text"
      },
      "source": [
        "目前為止，大致可以觀察到，直接使用簡單的模型以及訓練方式在這組數據上應該可以在訓練集和測試集上都得到一個還不錯的結果，說明這組資料其實不會很難。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1c05eJcg_jQ",
        "colab_type": "text"
      },
      "source": [
        "### 作業\n",
        "請嘗試使用 flip (左右翻轉) 來做 augmentation 以降低人臉關鍵點檢測的 loss\n",
        "\n",
        "Note: 圖像 flip 之後，groundtruth 的關鍵點也要跟著 flip 哦\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWJFmACZg_jS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_with_augment = get_model()\n",
        "model_with_augment.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXCJYS9Ig_jc",
        "colab_type": "code",
        "outputId": "d9367be2-65ab-4fb5-99fb-b55d69b2163e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ae63df914a09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimgaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmenters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0miaa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfliplr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'fliplr' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJfcSLHLd_yt",
        "colab_type": "code",
        "outputId": "d3a557f8-fbfb-4d23-ad04-645b31310b2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# training the model\n",
        "import numpy as np \n",
        "flip_model = model.fit(np.fliplr(imgs_train.reshape(-1, 96, 96, 1)), \n",
        "                       points_train, \n",
        "                       validation_split=0.2, batch_size=64, callbacks=[checkpoint, hist],\n",
        "                       shuffle=True, epochs=150, verbose=1)\n",
        "# save the model weights\n",
        "model.save_weights('weights.h5')\n",
        "# save the model\n",
        "model.save('model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1712 samples, validate on 428 samples\n",
            "Epoch 1/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.00189\n",
            "Epoch 2/150\n",
            "1712/1712 [==============================] - 12s 7ms/step - loss: 0.0012 - val_loss: 0.0019\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.00189 to 0.00186, saving model to best_weights.h5\n",
            "Epoch 3/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.00186\n",
            "Epoch 4/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 9.6887e-04 - val_loss: 0.0017\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00186 to 0.00172, saving model to best_weights.h5\n",
            "Epoch 5/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 8.5738e-04 - val_loss: 0.0015\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00172 to 0.00153, saving model to best_weights.h5\n",
            "Epoch 6/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 7.2542e-04 - val_loss: 0.0014\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00153 to 0.00143, saving model to best_weights.h5\n",
            "Epoch 7/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 6.3084e-04 - val_loss: 0.0013\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00143 to 0.00128, saving model to best_weights.h5\n",
            "Epoch 8/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 5.8036e-04 - val_loss: 0.0012\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00128 to 0.00118, saving model to best_weights.h5\n",
            "Epoch 9/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 5.1033e-04 - val_loss: 0.0011\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00118 to 0.00112, saving model to best_weights.h5\n",
            "Epoch 10/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 4.8059e-04 - val_loss: 0.0011\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00112 to 0.00108, saving model to best_weights.h5\n",
            "Epoch 11/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 4.4844e-04 - val_loss: 0.0011\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00108\n",
            "Epoch 12/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 4.2033e-04 - val_loss: 9.6919e-04\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00108 to 0.00097, saving model to best_weights.h5\n",
            "Epoch 13/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 3.8678e-04 - val_loss: 9.5685e-04\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00097 to 0.00096, saving model to best_weights.h5\n",
            "Epoch 14/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 3.7082e-04 - val_loss: 9.5823e-04\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00096\n",
            "Epoch 15/150\n",
            "1712/1712 [==============================] - 12s 7ms/step - loss: 3.6269e-04 - val_loss: 9.7536e-04\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.00096\n",
            "Epoch 16/150\n",
            "1712/1712 [==============================] - 12s 7ms/step - loss: 3.4525e-04 - val_loss: 8.7674e-04\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00096 to 0.00088, saving model to best_weights.h5\n",
            "Epoch 17/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 3.2753e-04 - val_loss: 9.0439e-04\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00088\n",
            "Epoch 18/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 3.2139e-04 - val_loss: 8.5684e-04\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00088 to 0.00086, saving model to best_weights.h5\n",
            "Epoch 19/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 3.0560e-04 - val_loss: 8.5842e-04\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00086\n",
            "Epoch 20/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 2.9438e-04 - val_loss: 8.4868e-04\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00086 to 0.00085, saving model to best_weights.h5\n",
            "Epoch 21/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 2.8398e-04 - val_loss: 8.5709e-04\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00085\n",
            "Epoch 22/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 2.8125e-04 - val_loss: 8.2993e-04\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00085 to 0.00083, saving model to best_weights.h5\n",
            "Epoch 23/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 2.8309e-04 - val_loss: 8.3430e-04\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00083\n",
            "Epoch 24/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 2.7253e-04 - val_loss: 8.2356e-04\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00083 to 0.00082, saving model to best_weights.h5\n",
            "Epoch 25/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 2.6062e-04 - val_loss: 8.1917e-04\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.00082 to 0.00082, saving model to best_weights.h5\n",
            "Epoch 26/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 2.5778e-04 - val_loss: 8.0882e-04\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.00082 to 0.00081, saving model to best_weights.h5\n",
            "Epoch 27/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 2.4756e-04 - val_loss: 8.0331e-04\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.00081 to 0.00080, saving model to best_weights.h5\n",
            "Epoch 28/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 2.4540e-04 - val_loss: 7.6951e-04\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.00080 to 0.00077, saving model to best_weights.h5\n",
            "Epoch 29/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 2.4063e-04 - val_loss: 7.8211e-04\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00077\n",
            "Epoch 30/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 2.4120e-04 - val_loss: 7.8549e-04\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00077\n",
            "Epoch 31/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 2.3037e-04 - val_loss: 7.9920e-04\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00077\n",
            "Epoch 32/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 2.2734e-04 - val_loss: 8.0096e-04\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00077\n",
            "Epoch 33/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 2.2406e-04 - val_loss: 8.1673e-04\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00077\n",
            "Epoch 34/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 2.1774e-04 - val_loss: 8.1243e-04\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00077\n",
            "Epoch 35/150\n",
            "1712/1712 [==============================] - 12s 7ms/step - loss: 2.1657e-04 - val_loss: 7.6916e-04\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.00077 to 0.00077, saving model to best_weights.h5\n",
            "Epoch 36/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 2.1137e-04 - val_loss: 8.0119e-04\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00077\n",
            "Epoch 37/150\n",
            "1712/1712 [==============================] - 12s 7ms/step - loss: 2.0712e-04 - val_loss: 7.7870e-04\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00077\n",
            "Epoch 38/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 2.0513e-04 - val_loss: 7.8013e-04\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00077\n",
            "Epoch 39/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.9750e-04 - val_loss: 7.7925e-04\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00077\n",
            "Epoch 40/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.9971e-04 - val_loss: 7.6942e-04\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00077\n",
            "Epoch 41/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.9172e-04 - val_loss: 8.0326e-04\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00077\n",
            "Epoch 42/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.9282e-04 - val_loss: 7.6202e-04\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.00077 to 0.00076, saving model to best_weights.h5\n",
            "Epoch 43/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.8576e-04 - val_loss: 7.9479e-04\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.00076\n",
            "Epoch 44/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.8837e-04 - val_loss: 7.6531e-04\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00076\n",
            "Epoch 45/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.8621e-04 - val_loss: 7.8085e-04\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00076\n",
            "Epoch 46/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.8304e-04 - val_loss: 7.9105e-04\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00076\n",
            "Epoch 47/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.8037e-04 - val_loss: 7.7777e-04\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00076\n",
            "Epoch 48/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.7429e-04 - val_loss: 7.8139e-04\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00076\n",
            "Epoch 49/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.7337e-04 - val_loss: 7.5715e-04\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.00076 to 0.00076, saving model to best_weights.h5\n",
            "Epoch 50/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.7467e-04 - val_loss: 7.7811e-04\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00076\n",
            "Epoch 51/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.7355e-04 - val_loss: 7.9268e-04\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.00076\n",
            "Epoch 52/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.7410e-04 - val_loss: 7.7496e-04\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.00076\n",
            "Epoch 53/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.7046e-04 - val_loss: 7.7219e-04\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.00076\n",
            "Epoch 54/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.6882e-04 - val_loss: 7.8666e-04\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.00076\n",
            "Epoch 55/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.7151e-04 - val_loss: 7.9485e-04\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.00076\n",
            "Epoch 56/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.6993e-04 - val_loss: 7.4893e-04\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.00076 to 0.00075, saving model to best_weights.h5\n",
            "Epoch 57/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.6396e-04 - val_loss: 7.8753e-04\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.00075\n",
            "Epoch 58/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.5906e-04 - val_loss: 7.8740e-04\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.00075\n",
            "Epoch 59/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.5874e-04 - val_loss: 7.6011e-04\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.00075\n",
            "Epoch 60/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.5740e-04 - val_loss: 7.7650e-04\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.00075\n",
            "Epoch 61/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.5627e-04 - val_loss: 7.7521e-04\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.00075\n",
            "Epoch 62/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.5363e-04 - val_loss: 7.5365e-04\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.00075\n",
            "Epoch 63/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.5204e-04 - val_loss: 7.5907e-04\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.00075\n",
            "Epoch 64/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.5036e-04 - val_loss: 7.8630e-04\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.00075\n",
            "Epoch 65/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.4673e-04 - val_loss: 7.5453e-04\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.00075\n",
            "Epoch 66/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.4518e-04 - val_loss: 7.9249e-04\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.00075\n",
            "Epoch 67/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.4437e-04 - val_loss: 8.0524e-04\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.00075\n",
            "Epoch 68/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.4720e-04 - val_loss: 7.8113e-04\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.00075\n",
            "Epoch 69/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.4661e-04 - val_loss: 8.0364e-04\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.00075\n",
            "Epoch 70/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.4093e-04 - val_loss: 7.5709e-04\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.00075\n",
            "Epoch 71/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.3919e-04 - val_loss: 7.6887e-04\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.00075\n",
            "Epoch 72/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.4108e-04 - val_loss: 7.9396e-04\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.00075\n",
            "Epoch 73/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.4023e-04 - val_loss: 8.0053e-04\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.00075\n",
            "Epoch 74/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.3677e-04 - val_loss: 7.7086e-04\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.00075\n",
            "Epoch 75/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.3806e-04 - val_loss: 7.9026e-04\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.00075\n",
            "Epoch 76/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.3424e-04 - val_loss: 7.6669e-04\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.00075\n",
            "Epoch 77/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.3585e-04 - val_loss: 7.5118e-04\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.00075\n",
            "Epoch 78/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.3437e-04 - val_loss: 7.8917e-04\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.00075\n",
            "Epoch 79/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.2945e-04 - val_loss: 7.7623e-04\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.00075\n",
            "Epoch 80/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.2901e-04 - val_loss: 7.4060e-04\n",
            "\n",
            "Epoch 00080: val_loss improved from 0.00075 to 0.00074, saving model to best_weights.h5\n",
            "Epoch 81/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.3409e-04 - val_loss: 7.4476e-04\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.00074\n",
            "Epoch 82/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.3472e-04 - val_loss: 7.6556e-04\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.00074\n",
            "Epoch 83/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.2834e-04 - val_loss: 7.8170e-04\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.00074\n",
            "Epoch 84/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.2472e-04 - val_loss: 7.5676e-04\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.00074\n",
            "Epoch 85/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.2421e-04 - val_loss: 7.9117e-04\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.00074\n",
            "Epoch 86/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.2475e-04 - val_loss: 7.4777e-04\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.00074\n",
            "Epoch 87/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.2173e-04 - val_loss: 7.6459e-04\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.00074\n",
            "Epoch 88/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.2290e-04 - val_loss: 7.5234e-04\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.00074\n",
            "Epoch 89/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.1752e-04 - val_loss: 7.9586e-04\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.00074\n",
            "Epoch 90/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.1732e-04 - val_loss: 7.5361e-04\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.00074\n",
            "Epoch 91/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.2016e-04 - val_loss: 7.6703e-04\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.00074\n",
            "Epoch 92/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.1834e-04 - val_loss: 7.6623e-04\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.00074\n",
            "Epoch 93/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.1754e-04 - val_loss: 7.7949e-04\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.00074\n",
            "Epoch 94/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.1670e-04 - val_loss: 8.2511e-04\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.00074\n",
            "Epoch 95/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.1754e-04 - val_loss: 7.3961e-04\n",
            "\n",
            "Epoch 00095: val_loss improved from 0.00074 to 0.00074, saving model to best_weights.h5\n",
            "Epoch 96/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.1590e-04 - val_loss: 7.7302e-04\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.00074\n",
            "Epoch 97/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.1382e-04 - val_loss: 7.5969e-04\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.00074\n",
            "Epoch 98/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.1153e-04 - val_loss: 7.5808e-04\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.00074\n",
            "Epoch 99/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.1247e-04 - val_loss: 7.7184e-04\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.00074\n",
            "Epoch 100/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.0947e-04 - val_loss: 7.5334e-04\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.00074\n",
            "Epoch 101/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.0788e-04 - val_loss: 7.5864e-04\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.00074\n",
            "Epoch 102/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.0914e-04 - val_loss: 8.0337e-04\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.00074\n",
            "Epoch 103/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.0933e-04 - val_loss: 7.7503e-04\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.00074\n",
            "Epoch 104/150\n",
            "1712/1712 [==============================] - 12s 7ms/step - loss: 1.1128e-04 - val_loss: 7.8858e-04\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.00074\n",
            "Epoch 105/150\n",
            "1712/1712 [==============================] - 13s 7ms/step - loss: 1.0616e-04 - val_loss: 7.4392e-04\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.00074\n",
            "Epoch 106/150\n",
            "1712/1712 [==============================] - 13s 8ms/step - loss: 1.0704e-04 - val_loss: 7.4668e-04\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.00074\n",
            "Epoch 107/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 1.0660e-04 - val_loss: 8.1069e-04\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.00074\n",
            "Epoch 108/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 1.1030e-04 - val_loss: 7.5671e-04\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.00074\n",
            "Epoch 109/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 1.0746e-04 - val_loss: 7.6608e-04\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.00074\n",
            "Epoch 110/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 1.0279e-04 - val_loss: 7.6157e-04\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.00074\n",
            "Epoch 111/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 1.0176e-04 - val_loss: 7.8672e-04\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.00074\n",
            "Epoch 112/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 1.0428e-04 - val_loss: 7.6726e-04\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.00074\n",
            "Epoch 113/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 1.0227e-04 - val_loss: 7.9509e-04\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.00074\n",
            "Epoch 114/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 1.0234e-04 - val_loss: 7.8416e-04\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.00074\n",
            "Epoch 115/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 9.9010e-05 - val_loss: 7.9730e-04\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.00074\n",
            "Epoch 116/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 1.0148e-04 - val_loss: 7.6337e-04\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.00074\n",
            "Epoch 117/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 1.0176e-04 - val_loss: 7.6565e-04\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.00074\n",
            "Epoch 118/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 9.7555e-05 - val_loss: 7.6894e-04\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.00074\n",
            "Epoch 119/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 9.8585e-05 - val_loss: 7.6135e-04\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.00074\n",
            "Epoch 120/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 9.9168e-05 - val_loss: 7.6301e-04\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.00074\n",
            "Epoch 121/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 9.8559e-05 - val_loss: 7.6640e-04\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.00074\n",
            "Epoch 122/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 9.7421e-05 - val_loss: 7.7148e-04\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.00074\n",
            "Epoch 123/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 9.4394e-05 - val_loss: 7.6362e-04\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.00074\n",
            "Epoch 124/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 9.6186e-05 - val_loss: 7.9439e-04\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.00074\n",
            "Epoch 125/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 9.6133e-05 - val_loss: 7.7183e-04\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.00074\n",
            "Epoch 126/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 9.5403e-05 - val_loss: 7.6882e-04\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.00074\n",
            "Epoch 127/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 9.4577e-05 - val_loss: 7.9471e-04\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.00074\n",
            "Epoch 128/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 9.2973e-05 - val_loss: 7.7904e-04\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.00074\n",
            "Epoch 129/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 9.6140e-05 - val_loss: 7.8040e-04\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.00074\n",
            "Epoch 130/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 9.3065e-05 - val_loss: 7.5510e-04\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.00074\n",
            "Epoch 131/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 9.1882e-05 - val_loss: 7.5210e-04\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.00074\n",
            "Epoch 132/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 9.1426e-05 - val_loss: 7.6545e-04\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.00074\n",
            "Epoch 133/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 9.2081e-05 - val_loss: 7.8088e-04\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.00074\n",
            "Epoch 134/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 8.8810e-05 - val_loss: 7.8468e-04\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.00074\n",
            "Epoch 135/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 8.8847e-05 - val_loss: 7.5769e-04\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.00074\n",
            "Epoch 136/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 8.9237e-05 - val_loss: 7.6985e-04\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.00074\n",
            "Epoch 137/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 8.7242e-05 - val_loss: 7.6239e-04\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.00074\n",
            "Epoch 138/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 8.7922e-05 - val_loss: 7.7373e-04\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.00074\n",
            "Epoch 139/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 8.8079e-05 - val_loss: 7.6454e-04\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.00074\n",
            "Epoch 140/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 8.7498e-05 - val_loss: 7.6191e-04\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.00074\n",
            "Epoch 141/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 8.8366e-05 - val_loss: 7.5621e-04\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.00074\n",
            "Epoch 142/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 8.8002e-05 - val_loss: 7.7275e-04\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.00074\n",
            "Epoch 143/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 8.4656e-05 - val_loss: 7.9141e-04\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.00074\n",
            "Epoch 144/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 8.5596e-05 - val_loss: 7.9986e-04\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.00074\n",
            "Epoch 145/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 8.6993e-05 - val_loss: 7.3439e-04\n",
            "\n",
            "Epoch 00145: val_loss improved from 0.00074 to 0.00073, saving model to best_weights.h5\n",
            "Epoch 146/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 8.7665e-05 - val_loss: 7.9247e-04\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.00073\n",
            "Epoch 147/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 8.3334e-05 - val_loss: 7.7206e-04\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.00073\n",
            "Epoch 148/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 8.3330e-05 - val_loss: 7.4809e-04\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.00073\n",
            "Epoch 149/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 8.4874e-05 - val_loss: 7.8352e-04\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.00073\n",
            "Epoch 150/150\n",
            "1712/1712 [==============================] - 15s 9ms/step - loss: 8.3868e-05 - val_loss: 7.6130e-04\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.00073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Wlrpdx3d5Sx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs_train.reshape(-1, 96, 96, 1).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdHPzIy7f3Wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss 值的圖\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.title('Optimizer : Adam', fontsize=10)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.plot(flip_model.history['loss'], color='b', label='Training Loss')\n",
        "plt.plot(flip_model.history['val_loss'], color='r', label='Validation Loss')\n",
        "plt.legend(loc='upper right')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awm-1eMMT1U_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}